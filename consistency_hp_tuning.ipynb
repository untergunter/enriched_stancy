{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from transformers import BertConfig,BertModel\n",
    "from transformers import BertTokenizer,AdamW\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler\n",
    "from torch.nn import CrossEntropyLoss, CosineEmbeddingLoss\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "\n",
    "def test_consistency_model(model, dataloader, device):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            together_ids, together_masks, claim_ids, claim_masks, labels = batch\n",
    "            together_ids = together_ids.to(device)\n",
    "            together_masks = together_masks.to(device)\n",
    "            claim_ids = claim_ids.to(device)\n",
    "            claim_masks = claim_masks.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            model_prediction = model.predict(together_ids,\n",
    "                              together_masks,\n",
    "                              claim_ids,\n",
    "                              claim_masks,\n",
    "                              )\n",
    "            y_true += [int(label) for label in labels]\n",
    "            y_pred += [int(label) for label in model_prediction]\n",
    "    return y_true,y_pred\n",
    "\n",
    "def find_file(files_list,file_name):\n",
    "    for file in files_list:\n",
    "        if file.split(os.sep)[-1] == file_name:\n",
    "            return file\n",
    "    return None\n",
    "\n",
    "def get_paper_train_dev_test():\n",
    "    all_tsv = glob('./**/*.tsv', recursive=True)\n",
    "    dev = find_file(all_tsv,'dev.tsv')\n",
    "    dev = pd.read_csv(dev,\n",
    "                      sep='\\t',\n",
    "                      names=['index','text','perspective','stance_label_3']) if dev else None\n",
    "    train = find_file(all_tsv, 'train.tsv')\n",
    "    train = pd.read_csv(train,\n",
    "                      sep='\\t',\n",
    "                      names=['index', 'text', 'perspective', 'stance_label_3']) if train else None\n",
    "\n",
    "    test = find_file(all_tsv, 'test.tsv')\n",
    "    test = pd.read_csv(test,\n",
    "                        sep='\\t',\n",
    "                        names=['index', 'text', 'perspective', 'stance_label_3']) if test else None\n",
    "\n",
    "    return train,dev,test\n",
    "\n",
    "def make_tokenizer():\n",
    "    tknzr = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def tokenize_list_of_strings(list_of_strings):\n",
    "        ids, attentions = [], []\n",
    "        for input_string in list_of_strings:\n",
    "            encoded = tknzr.encode_plus(input_string,\n",
    "                                        add_special_tokens=False,\n",
    "                                        truncation=True,\n",
    "                                        padding='max_length',\n",
    "                                        max_length=100,\n",
    "\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt'\n",
    "                                        )\n",
    "            id_tensor = encoded['input_ids']\n",
    "            attention_tensor = encoded['attention_mask']\n",
    "            ids.append(id_tensor)\n",
    "            attentions.append(attention_tensor)\n",
    "        ids = torch.cat(ids, dim=0)\n",
    "        attentions = torch.cat(attentions, dim=0)\n",
    "        return ids, attentions\n",
    "\n",
    "    return tokenize_list_of_strings\n",
    "\n",
    "def make_2_kinds_data_set(raw_data,batch_size:int=24):\n",
    "\n",
    "\n",
    "    claim = '[CLS] ' + raw_data['text'].str.strip() + ' [SEP]'\n",
    "    perspective = raw_data['perspective'].str.strip() + ' [SEP]'\n",
    "    together = claim + perspective\n",
    "\n",
    "    label =[1 if single_label=='supports' else 0 for single_label in raw_data['stance_label_3'] ]\n",
    "\n",
    "    preprocessor = make_tokenizer()\n",
    "\n",
    "    claim_ids,claim_masks = preprocessor(claim)\n",
    "    together_ids,together_masks = preprocessor(together)\n",
    "    labels = torch.tensor(label)\n",
    "\n",
    "\n",
    "    together_only_dataset = TensorDataset(together_ids,\n",
    "                                          together_masks,\n",
    "                                          labels)\n",
    "    together_and_claim_dataset = TensorDataset(together_ids,\n",
    "                                               together_masks,\n",
    "                                               claim_ids,\n",
    "                                               claim_masks,\n",
    "                                               labels)\n",
    "\n",
    "    together_only_loader = DataLoader(\n",
    "        together_only_dataset,\n",
    "        sampler=RandomSampler(together_only_dataset),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    together_and_claim_loader = DataLoader(\n",
    "        together_and_claim_dataset,\n",
    "        sampler=RandomSampler(together_and_claim_dataset),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # together_only_loader->claim_ids, claim_masks, labels\n",
    "    # together_and_claim_loader->together_ids,together_masks,\n",
    "    # claim_ids,claim_masks,labels\n",
    "\n",
    "    return together_only_loader,together_and_claim_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class DoubleLoss(nn.Module):\n",
    "\n",
    "    def __init__(self,device):\n",
    "        super(DoubleLoss, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        bert_config = BertConfig.from_pretrained('bert-base-uncased',\n",
    "                                                 output_hidden_states=True)\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                              config=bert_config)\n",
    "        self.stance = nn.Linear(769, 2)\n",
    "        self.cosine = nn.CosineSimilarity()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.similarity_cosine_loss = CosineEmbeddingLoss()\n",
    "        self.stance_loss_func = CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, both_ids, both_mask, claim_ids, claim_mask,labels = None):\n",
    "\n",
    "        both_hs = self.bert(both_ids, attention_mask=both_mask).pooler_output\n",
    "        both_hs = self.dropout(both_hs)\n",
    "\n",
    "        claim_hs = self.bert(claim_ids, attention_mask=claim_mask).pooler_output\n",
    "\n",
    "        cos_sim = self.cosine(both_hs, claim_hs).unsqueeze(1)\n",
    "        combined = torch.cat([both_hs, cos_sim], dim=1)\n",
    "        probabilities = self.stance(combined)\n",
    "\n",
    "        if labels is not None:\n",
    "\n",
    "            # first loss\n",
    "\n",
    "            stance_loss = \\\n",
    "                self.stance_loss_func(probabilities.view(-1,2),\n",
    "                                 labels.view(-1))\n",
    "\n",
    "            # second loss\n",
    "            similarity_labels = torch.ones(labels.shape,device=self.device)\n",
    "            similarity_labels[ labels == 0 ] = -1\n",
    "\n",
    "            loss_claim = self.similarity_cosine_loss(both_hs,\n",
    "                                                 claim_hs,\n",
    "                                                 similarity_labels.float())\n",
    "\n",
    "            loss = stance_loss + loss_claim\n",
    "\n",
    "            return loss\n",
    "\n",
    "        return combined, probabilities\n",
    "\n",
    "    def predict(self,both_ids, both_mask, claim_ids, claim_mask):\n",
    "        combined, probabilities = self.forward(both_ids, both_mask, claim_ids, claim_mask)\n",
    "        _, predicted = torch.max(probabilities, 1)\n",
    "        return predicted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train_consistency():\n",
    "\n",
    "    train, dev, test = get_paper_train_dev_test()\n",
    "    train_together_only_loader, train_together_and_claim_loader = \\\n",
    "        make_2_kinds_data_set(train,12)\n",
    "    dev_together_only_loader, dev_together_and_claim_loader = \\\n",
    "        make_2_kinds_data_set(dev,12)\n",
    "    test_together_only_loader, test_together_and_claim_loader = \\\n",
    "        make_2_kinds_data_set(test,12)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = DoubleLoss(device).to(device)\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr=2e-5,\n",
    "                      eps=1e-8\n",
    "                      )\n",
    "    losses = []\n",
    "    f1s = []\n",
    "    accuracy_list = []\n",
    "    recalls = []\n",
    "    seconds = []\n",
    "    epochs = []\n",
    "\n",
    "    # add the basic performance\n",
    "    y_true, y_pred = test_consistency_model(model, dev_together_and_claim_loader, device)\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "\n",
    "    losses.append(-1)\n",
    "    f1s.append(weighted_f1)\n",
    "    accuracy_list.append(precision)\n",
    "    recalls.append(recall)\n",
    "    seconds.append(-1)\n",
    "    epochs.append(-1)\n",
    "    print(f'epoch:{-1}, loss:{-1}, f1:{weighted_f1} ,precision:{precision} ,recall:{recall} ,seconds:{-1}')\n",
    "\n",
    "    for epoch in range(8):\n",
    "        start_time = datetime.now()\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in train_together_and_claim_loader:\n",
    "            model.zero_grad()\n",
    "            together_ids, together_masks, claim_ids, claim_masks, labels = batch\n",
    "\n",
    "            together_ids = together_ids.to(device)\n",
    "            together_masks = together_masks.to(device)\n",
    "            claim_ids = claim_ids.to(device)\n",
    "            claim_masks = claim_masks.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            loss = model(\n",
    "                        together_ids,\n",
    "                        together_masks,\n",
    "                        claim_ids,\n",
    "                        claim_masks,\n",
    "                        labels\n",
    "                        )\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "        y_true, y_pred = test_consistency_model(model, dev_together_and_claim_loader, device)\n",
    "        end_time = datetime.now()\n",
    "        total_seconds = (end_time-start_time).seconds\n",
    "\n",
    "        weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "\n",
    "        seconds.append(total_seconds)\n",
    "        losses.append(total_loss)\n",
    "        f1s.append(weighted_f1)\n",
    "        recalls.append(recall)\n",
    "        accuracy_list.append(precision)\n",
    "        epochs.append(epoch)\n",
    "\n",
    "\n",
    "        print(f'epoch:{epoch}, loss:{total_loss}, f1:{weighted_f1} ,precision:{precision} ,recall:{recall} ,seconds:{total_seconds}')\n",
    "\n",
    "\n",
    "    # add the test set performance\n",
    "    y_true, y_pred = test_consistency_model(model, test_together_and_claim_loader, device)\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "\n",
    "    losses.append(-2)\n",
    "    f1s.append(weighted_f1)\n",
    "    accuracy_list.append(precision)\n",
    "    recalls.append(recall)\n",
    "    seconds.append(-2)\n",
    "    epochs.append(-2)\n",
    "    print(f'epoch:{-2}, loss:{-2}, f1:{weighted_f1} ,precision:{precision}  ,recall:{recall} ,seconds:{-2}')\n",
    "\n",
    "    results_df = pd.DataFrame({\"epoch\":epochs,\n",
    "                               'loss':losses,\n",
    "                               'f1':f1s,\n",
    "                               'precision':accuracy_list,\n",
    "                               'recall':recalls,\n",
    "                               'seconds':total_seconds})\n",
    "    results_df.to_csv('results/bert_consistency_results.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "print('ready')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_33936/3854379328.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain_consistency\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_33936/2080378468.py\u001B[0m in \u001B[0;36mtrain_consistency\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0mmake_2_kinds_data_set\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdev\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m12\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mtest_together_only_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_together_and_claim_loader\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m         \u001B[0mmake_2_kinds_data_set\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m12\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"cuda\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"cpu\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_33936/1196946935.py\u001B[0m in \u001B[0;36mmake_2_kinds_data_set\u001B[0;34m(raw_data, batch_size)\u001B[0m\n\u001B[1;32m     81\u001B[0m     \u001B[0mlabel\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0msingle_label\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;34m'supports'\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0msingle_label\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mraw_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'stance_label_3'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 83\u001B[0;31m     \u001B[0mpreprocessor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmake_tokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     84\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m     \u001B[0mclaim_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mclaim_masks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpreprocessor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclaim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_33936/1196946935.py\u001B[0m in \u001B[0;36mmake_tokenizer\u001B[0;34m()\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mmake_tokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m     \u001B[0mtknzr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBertTokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'bert-base-uncased'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtokenize_list_of_strings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist_of_strings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001B[0m\n\u001B[1;32m   1683\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1684\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1685\u001B[0;31m                     resolved_vocab_files[file_id] = cached_path(\n\u001B[0m\u001B[1;32m   1686\u001B[0m                         \u001B[0mfile_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1687\u001B[0m                         \u001B[0mcache_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcache_dir\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/transformers/file_utils.py\u001B[0m in \u001B[0;36mcached_path\u001B[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001B[0m\n\u001B[1;32m   1361\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mis_remote_url\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl_or_filename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1362\u001B[0m         \u001B[0;31m# URL, so get it from the cache (downloading if necessary)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1363\u001B[0;31m         output_path = get_from_cache(\n\u001B[0m\u001B[1;32m   1364\u001B[0m             \u001B[0murl_or_filename\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1365\u001B[0m             \u001B[0mcache_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcache_dir\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/transformers/file_utils.py\u001B[0m in \u001B[0;36mget_from_cache\u001B[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001B[0m\n\u001B[1;32m   1531\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mlocal_files_only\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1532\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1533\u001B[0;31m             \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrequests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_redirects\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproxies\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mproxies\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0metag_timeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1534\u001B[0m             \u001B[0mr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_for_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1535\u001B[0m             \u001B[0metag\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mheaders\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"X-Linked-Etag\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mheaders\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ETag\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/requests/api.py\u001B[0m in \u001B[0;36mhead\u001B[0;34m(url, **kwargs)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetdefault\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'allow_redirects'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 102\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'head'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/requests/api.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0;31m# cases, and look like a memory leak in others.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0msessions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSession\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msession\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/requests/sessions.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    540\u001B[0m         }\n\u001B[1;32m    541\u001B[0m         \u001B[0msend_kwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msettings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 542\u001B[0;31m         \u001B[0mresp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0msend_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    543\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    544\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/requests/sessions.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    653\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    654\u001B[0m         \u001B[0;31m# Send the request\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 655\u001B[0;31m         \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0madapter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    656\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    657\u001B[0m         \u001B[0;31m# Total elapsed time of the request (approximately)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/requests/adapters.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mchunked\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 439\u001B[0;31m                 resp = conn.urlopen(\n\u001B[0m\u001B[1;32m    440\u001B[0m                     \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    441\u001B[0m                     \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    697\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    698\u001B[0m             \u001B[0;31m# Make the request on the httplib connection object.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 699\u001B[0;31m             httplib_response = self._make_request(\n\u001B[0m\u001B[1;32m    700\u001B[0m                 \u001B[0mconn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    701\u001B[0m                 \u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    443\u001B[0m                     \u001B[0;31m# Python 3 (including for exceptions like SystemExit).\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    444\u001B[0m                     \u001B[0;31m# Otherwise it looks like a bug in the code.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 445\u001B[0;31m                     \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    446\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mSocketTimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBaseSSLError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSocketError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    447\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_raise_timeout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mread_timeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/urllib3/packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    438\u001B[0m                 \u001B[0;31m# Python 3\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    439\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 440\u001B[0;31m                     \u001B[0mhttplib_response\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetresponse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    441\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m                     \u001B[0;31m# Remove the TypeError from the exception chain in\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/http/client.py\u001B[0m in \u001B[0;36mgetresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1342\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1343\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1344\u001B[0;31m                 \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbegin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1345\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mConnectionError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1346\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/http/client.py\u001B[0m in \u001B[0;36mbegin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    305\u001B[0m         \u001B[0;31m# read until we get a non-100 response\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 307\u001B[0;31m             \u001B[0mversion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstatus\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreason\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    308\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mstatus\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mCONTINUE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/http/client.py\u001B[0m in \u001B[0;36m_read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    266\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_read_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 268\u001B[0;31m         \u001B[0mline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_MAXLINE\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"iso-8859-1\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    269\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0m_MAXLINE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mLineTooLong\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"status line\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    667\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    668\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 669\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    670\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    671\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_timeout_occurred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/ssl.py\u001B[0m in \u001B[0;36mrecv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1239\u001B[0m                   \u001B[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001B[0m \u001B[0;34m%\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1240\u001B[0m                   self.__class__)\n\u001B[0;32m-> 1241\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnbytes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1242\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1243\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbuffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnbytes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/trans/lib/python3.8/ssl.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1097\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1098\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mbuffer\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1099\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1100\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1101\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_consistency()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_to_result_csv(loss,f1,accuracy,\n",
    "                      recall,seconds,epoch,hp):\n",
    "  df = pd.DataFrame({  'epoch':[epoch],\n",
    "                       'loss':[loss],\n",
    "                       'f1':[f1],\n",
    "                       'accuracy':[accuracy],\n",
    "                       'recall':[recall],\n",
    "                       'seconds':[seconds],\n",
    "                       'hyper_parameters':[str(hp)]})\n",
    "\n",
    "  df.to_csv('drive/MyDrive/bert_consistency_hp_opt.csv',\n",
    "            header=False,mode='a',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}